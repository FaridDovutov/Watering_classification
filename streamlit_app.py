import streamlit as st
import pandas as pd
import joblib
import numpy as np
import warnings
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.preprocessing import MinMaxScaler

warnings.filterwarnings("ignore")

# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
@st.cache_resource
def load_model_and_processors():
    try:
        model = joblib.load('xgboost_model.pkl')
        imputer = joblib.load('imputer.pkl')
        scaler = joblib.load('scaler.pkl')
        return model, imputer, scaler
    except FileNotFoundError:
        st.error("–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ 'xgboost_model.pkl', 'imputer.pkl' –∏ 'scaler.pkl' –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ç–æ–π –∂–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.")
        return None, None, None

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
model, imputer, scaler = load_model_and_processors()
if model is None:
    st.stop()

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title('–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ –ø–æ–ª–∏–≤–µ —Ä–∞—Å—Ç–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç–æ–¥–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è')

# --- –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ---
st.header("–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ")
st.markdown("–≠—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –Ω–µ–≤–∏–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –æ–Ω–∏ –±—ã–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã)
try:
    X_test_scaled_for_metrics = joblib.load('X_test_scaled.pkl')
    y_test_for_metrics = joblib.load('y_test.pkl')
except FileNotFoundError:
    st.warning("–§–∞–π–ª—ã —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –±—É–¥—É—Ç –æ—Ç–æ–±—Ä–∞–∂–µ–Ω—ã.")
    X_test_scaled_for_metrics = None
    y_test_for_metrics = None

if X_test_scaled_for_metrics is not None:
    y_pred_proba_test = model.predict_proba(X_test_scaled_for_metrics)[:, 1]
    y_pred_test = (y_pred_proba_test > 0.5).astype(int)

    accuracy = accuracy_score(y_test_for_metrics, y_pred_test)
    precision = precision_score(y_test_for_metrics, y_pred_test, zero_division=0)
    recall = recall_score(y_test_for_metrics, y_pred_test, zero_division=0)
    f1 = f1_score(y_test_for_metrics, y_pred_test, zero_division=0)
    roc_auc = roc_auc_score(y_test_for_metrics, y_pred_proba_test)
    conf_matrix = confusion_matrix(y_test_for_metrics, y_pred_test)

    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.metric("Accuracy", f"{accuracy:.4f}")
    with col2:
        st.metric("Precision", f"{precision:.4f}")
    with col3:
        st.metric("Recall", f"{recall:.4f}")
    with col4:
        st.metric("F1 Score", f"{f1:.4f}")
    with col5:
        st.metric("ROC AUC", f"{roc_auc:.4f}")

    st.write("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ:")
    st.dataframe(pd.DataFrame(conf_matrix,
                              index=['True Negative', 'True Positive'],
                              columns=['Predicted Negative', 'Predicted Positive']))
else:
    st.info("–ß—Ç–æ–±—ã –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏, –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –æ–±—É—á–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ 'X_test_scaled.pkl' –∏ 'y_test.pkl'.")

# --- –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –¥–ª—è –≤–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö ---
st.sidebar.header("–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞")

feature_ranges = {
    'Temperature': (0, 50),
    ' Soil Humidity': (0, 100),
    'Time': (0, 24),
    'Air temperature (C)': (-10, 50),
    'Wind speed (Km/h)': (0, 150),
    'Air humidity (%)': (0, 100),
    'Wind gust (Km/h)': (0, 200),
    'Pressure (KPa)': (90, 110),
    'ph': (0, 14),
    'rainfall': (0, 1000),
    'N': (0, 1000),
    'P': (0, 1000),
    'K': (0, 1000),
}

input_data = {}
for feature, (min_val, max_val) in feature_ranges.items():
    input_data[feature] = st.sidebar.slider(
        f'–ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è "{feature}"',
        min_value=float(min_val),
        max_value=float(max_val),
        value=float((min_val + max_val) / 2)
    )

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞
if st.sidebar.button('–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑'):
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤–≤–µ–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ DataFrame
        user_input_df = pd.DataFrame([input_data])

        # –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        user_input_df['Temp_Humidity_Interaction'] = user_input_df['Temperature'] * user_input_df[' Soil Humidity']
        user_input_df['NPK_Total'] = user_input_df['N'] + user_input_df['P'] + user_input_df['K']
        user_input_df['Pressure_Humidity_Ratio'] = user_input_df['Pressure (KPa)'] / user_input_df['Air humidity (%)']
        user_input_df = user_input_df.replace([np.inf, -np.inf], np.nan)

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–º–ø—å—é—Ç–µ—Ä–∞ –∏ —Å–∫–µ–π–ª–µ—Ä–∞
        user_input_imp = imputer.transform(user_input_df)
        user_input_scaled = scaler.transform(user_input_imp)

        # –ü—Ä–æ–≥–Ω–æ–∑
        prediction = model.predict(user_input_scaled)
        prediction_proba = model.predict_proba(user_input_scaled)[:, 1]

        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        st.subheader("–ü—Ä–æ–≥–Ω–æ–∑ –º–æ–¥–µ–ª–∏")
        if prediction[0] == 1:
            st.success(f"–ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ **–ø–æ–ª–∏–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º.** üíß")
        else:
            st.info(f"–ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ **–ø–æ–ª–∏–≤ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.** üå±")
        st.write(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ (–ø–æ–ª–∏–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º): {prediction_proba[0]:.2f}")

    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
